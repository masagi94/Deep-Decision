{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbfa55c7",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5055d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.setLogLevel(0)\n",
    "import numpy as np\n",
    "import socket\n",
    "import queue\n",
    "import threading\n",
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "import warnings\n",
    "\n",
    "battery = psutil.sensors_battery()\n",
    "# torch.set_num_threads(20)\n",
    "# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3866375b",
   "metadata": {},
   "source": [
    "## CUSTOM CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b3c7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPS:\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "        self.new_latency = 0\n",
    "        self.prev_latency = 0\n",
    "        self.avg_latency = 0\n",
    "        self.num_frames = 0\n",
    "        self.avg_fps = 0\n",
    "        self.fps_threshold = 1\n",
    "        self.text = \"\"\n",
    "    \n",
    "    def start(self):\n",
    "        self.new_latency = time.time()\n",
    "    \n",
    "    def update(self):\n",
    "        \n",
    "        self.num_frames += 1\n",
    "        \n",
    "        # perform FPS calculations\n",
    "        if (time.time() - self.start_time) > self.fps_threshold:\n",
    "            self.avg_latency = round(1000*(self.new_latency - self.prev_latency))\n",
    "            self.avg_fps = int(self.num_frames/(time.time() - self.start_time))\n",
    "            self.text = \"FPS: \" + str(self.avg_fps) + \"  Latency: \" + str(self.avg_latency) + \" ms\"\n",
    "            self.num_frames = 0\n",
    "            self.start_time = time.time()\n",
    "        \n",
    "        self.prev_latency = self.new_latency\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2fa3eb",
   "metadata": {},
   "source": [
    "## HELPER METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995ce2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive_detections(run_receive_thread,sock,detections_queue):\n",
    "\n",
    "    while (run_receive_thread):\n",
    "        detection, addr = sock.recvfrom(65535)\n",
    "        detections_queue.put(detection)\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd46f891",
   "metadata": {},
   "source": [
    "### LOCAL YOLO MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13575a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_local_model():\n",
    "    # import small YOLO model\n",
    "    model = torch.hub.load('Ultralytics/yolov5', 'yolov5s').to(\"cpu\")\n",
    "\n",
    "    # Set Video Properties\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    text_font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    white = (255,255,255)\n",
    "    red = (0,0,255)\n",
    "    black = (0,0,0)\n",
    "    fps = FPS()\n",
    "\n",
    "    confidence_fps_count = 0\n",
    "    avg_fps = 0\n",
    "\n",
    "    \n",
    "    print(\"\\n\\n***********************\")\n",
    "    print(\"\\nRUNNING LOCAL MODEL...\")\n",
    "    print(\"\\n***********************\")\n",
    "    while True:\n",
    "        # Capture frame from webcam, get predictions\n",
    "        fps.start()\n",
    "        ret, frame = cap.read()\n",
    "        results = model(frame)\n",
    "        results = np.array(results.pandas().xyxy[0])\n",
    "        temp_img = np.copy(frame)\n",
    "        \n",
    "        if(len(results) > 0):\n",
    "            # draw text and bounding boxes for each detection\n",
    "            for box in results:\n",
    "                x1,y1 = int(box[0]),int(box[1])\n",
    "                x2,y2 = int(box[2]),int(box[3])\n",
    "                rounded_confidence = round(box[4], 2)\n",
    "                prediction_text = box[6] + \"  \"+ str(rounded_confidence)\n",
    "                (text_w, _), _ = cv2.getTextSize(prediction_text, text_font, .6, 1)\n",
    "                cv2.rectangle(temp_img, (x1,y1), (x2,y2),red, 3)\n",
    "                cv2.rectangle(temp_img, (x1, y1 - 25), (x1 + text_w, y1), red, -1)\n",
    "                cv2.putText(temp_img, prediction_text,(x1 ,y1 - 10), text_font, .6, white, 1, cv2.LINE_AA)\n",
    "\n",
    "            confidence_fps_count += 1\n",
    "            avg_fps += fps.avg_fps\n",
    "            avg_fps /= 2\n",
    "        \n",
    "        # draw text and background for FPS and Latency\n",
    "        cv2.rectangle(temp_img, (0,0),(220, 32), black, -1)\n",
    "        cv2.putText(temp_img, fps.text, (7,20), text_font, .5, white, 1, cv2.LINE_AA)           \n",
    "        cv2.imshow(\"Local Processing\",temp_img)\n",
    "\n",
    "        fps.update()\n",
    "        battery = psutil.sensors_battery()\n",
    "        \n",
    "        \n",
    "        ## *********************************** ##\n",
    "        #  Check if we should quit local model  #\n",
    "        ## *********************************** ##\n",
    "        \n",
    "        if((battery.percent < 80) and (not battery.power_plugged)):\n",
    "            print(\"\\n\\nBATTERY UNPLUGGED AND BELOW THRESHOLD, QUITTING LOCAL MODEL\")\n",
    "            print(\"Current battery:\",battery.percent)\n",
    "            break\n",
    "        \n",
    "        if(confidence_fps_count >= 300):\n",
    "            if(avg_fps < 10):\n",
    "                print(\"\\n\\nFPS TOO LOW, QUITTING LOCAL MODEL\")\n",
    "                break\n",
    "            \n",
    "            confidence_fps_count = 0\n",
    "            avg_fps = 0\n",
    "\n",
    "        # Wait for 1 millisecond, and check if the user pressed the 'q' key or the window was closed\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Graceful Shutdown\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29528217",
   "metadata": {},
   "source": [
    "### REMOTE PROCESSING ON SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "046b894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_remote_model():\n",
    "    # Define IP address and port number of the client, setup socket\n",
    "    ip = '192.168.1.189'\n",
    "    port = 5005\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "\n",
    "    # setup receiving thread\n",
    "    detections_queue = queue.Queue()\n",
    "    run_receive_thread = True\n",
    "    t1 = threading.Thread(target=receive_detections, args=(run_receive_thread,sock,detections_queue,))\n",
    "    t1.start()\n",
    "\n",
    "    # Create video capture object\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 70]\n",
    "\n",
    "    text_font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    white = (255,255,255)\n",
    "    red = (0,0,255)\n",
    "    black = (0,0,0)\n",
    "    \n",
    "    fps = FPS()\n",
    "    confidence_fps_count = 0\n",
    "    avg_fps = 0\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n***********************\")\n",
    "    print(\"\\nRUNNING REMOTE MODEL...\")\n",
    "    print(\"\\n***********************\")\n",
    "    \n",
    "    while True:\n",
    "        # Capture frame from webcam, keep track of fps\n",
    "        fps.start()\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Encode frame as JPEG, convert to bytes\n",
    "        _, img_encoded = cv2.imencode('.jpg', frame, encode_param)\n",
    "        data = np.array(img_encoded)\n",
    "        string_data = data.tobytes()\n",
    "\n",
    "        # Send frame to client\n",
    "        try:\n",
    "            sock.sendto(string_data, (ip, port))\n",
    "        except:\n",
    "            print(\"ERROR - FRAME NOT SENT\")\n",
    "\n",
    "        # render frames with FPS + latency overlay\n",
    "        while not detections_queue.empty():\n",
    "            detection = detections_queue.get()\n",
    "            img_encoded = np.frombuffer(detection, dtype=np.uint8)\n",
    "            img = cv2.imdecode(img_encoded, cv2.IMREAD_COLOR)[:,:,::-1]\n",
    "            temp_img = np.copy(img)\n",
    "\n",
    "            # draw text and background for FPS and Latency\n",
    "            cv2.rectangle(temp_img, (0,0),(220, 32), black, -1)\n",
    "            cv2.putText(temp_img, fps.text, (7,20), text_font, .5, white, 1, cv2.LINE_AA)             \n",
    "            cv2.imshow(\"Remote Processing\",temp_img)\n",
    "\n",
    "            fps.update()\n",
    "            \n",
    "            confidence_fps_count += 1\n",
    "            avg_fps += fps.avg_fps\n",
    "            avg_fps /= 2\n",
    "        \n",
    "        \n",
    "        ## ************************************ ##\n",
    "        #  Check if we should quit remote model  #\n",
    "        ## ************************************ ##\n",
    "        if(confidence_fps_count >= 50 ):\n",
    "            if(fps.avg_latency > 300):\n",
    "                print(\"\\n\\nLATENCY TOO HIGH, QUITTING REMOTE MODEL \")\n",
    "                print(\"Average Latency:\", fps.avg_latency, \"ms\")\n",
    "                break\n",
    "            if(avg_fps < 10):\n",
    "                print(\"\\n\\nFPS TOO LOW, QUITTING REMOTE MODEL\")\n",
    "                print(\"Average FPS:\", avg_fps)\n",
    "                break\n",
    "            \n",
    "            confidence_fps_count = 0\n",
    "            avg_fps = 0\n",
    "\n",
    "        \n",
    "        # Wait for 1 millisecond, and check if the user pressed 'q'\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Graceful shutdown \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    run_receive_thread = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f79dd4",
   "metadata": {},
   "source": [
    "# DEEP DECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "409546e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/mauro/.cache/torch/hub/Ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2023-4-18 Python-3.9.16 torch-2.0.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /Users/mauro/.cache/torch/hub/requirements.txt not found, check failed.\n",
      "\n",
      "\n",
      "***********************\n",
      "\n",
      "RUNNING LOCAL MODEL...\n",
      "\n",
      "***********************\n",
      "\n",
      "\n",
      "BATTERY UNPLUGGED AND BELOW THRESHOLD, QUITTING LOCAL MODEL\n",
      "Current battery: 73\n",
      "\n",
      "\n",
      "***********************\n",
      "\n",
      "RUNNING REMOTE MODEL...\n",
      "\n",
      "***********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/mauro/.cache/torch/hub/Ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2023-4-18 Python-3.9.16 torch-2.0.0 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /Users/mauro/.cache/torch/hub/requirements.txt not found, check failed.\n",
      "\n",
      "\n",
      "***********************\n",
      "\n",
      "RUNNING LOCAL MODEL...\n",
      "\n",
      "***********************\n",
      "\n",
      "\n",
      "BATTERY UNPLUGGED AND BELOW THRESHOLD, QUITTING LOCAL MODEL\n",
      "Current battery: 73\n",
      "\n",
      "\n",
      "***********************\n",
      "\n",
      "RUNNING REMOTE MODEL...\n",
      "\n",
      "***********************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     run_local_model()\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mrun_remote_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 60\u001b[0m, in \u001b[0;36mrun_remote_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m cv2\u001b[38;5;241m.\u001b[39mrectangle(temp_img, (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m),(\u001b[38;5;241m220\u001b[39m, \u001b[38;5;241m32\u001b[39m), black, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     59\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(temp_img, fps\u001b[38;5;241m.\u001b[39mtext, (\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m20\u001b[39m), text_font, \u001b[38;5;241m.5\u001b[39m, white, \u001b[38;5;241m1\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mLINE_AA)             \n\u001b[0;32m---> 60\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRemote Processing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtemp_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m fps\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     64\u001b[0m confidence_fps_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run indefinitely\n",
    "while True:\n",
    "    run_local_model()\n",
    "    run_remote_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
